{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650deacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff76ebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niraj\\AppData\\Local\\Temp\\ipykernel_8212\\185665647.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\niraj\\AppData\\Local\\Temp\\ipykernel_8212\\185665647.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\niraj\\AppData\\Local\\Temp\\ipykernel_8212\\185665647.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\niraj\\AppData\\Local\\Temp\\ipykernel_8212\\185665647.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "c:\\Users\\niraj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.4793 - loss: 0.7450 - val_accuracy: 0.6869 - val_loss: 0.6518\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6803 - loss: 0.6494 - val_accuracy: 0.7172 - val_loss: 0.6138\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7560 - loss: 0.5911 - val_accuracy: 0.7273 - val_loss: 0.5881\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7486 - loss: 0.5840 - val_accuracy: 0.7576 - val_loss: 0.5642\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7850 - loss: 0.5378 - val_accuracy: 0.7879 - val_loss: 0.5426\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8167 - loss: 0.4945 - val_accuracy: 0.7980 - val_loss: 0.5273\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8307 - loss: 0.4861 - val_accuracy: 0.7980 - val_loss: 0.5143\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8288 - loss: 0.4971 - val_accuracy: 0.7980 - val_loss: 0.5056\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7898 - loss: 0.5104 - val_accuracy: 0.7980 - val_loss: 0.4989\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7938 - loss: 0.5008 - val_accuracy: 0.7980 - val_loss: 0.4955\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8219 - loss: 0.4830 - val_accuracy: 0.7980 - val_loss: 0.4962\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8341 - loss: 0.4420 - val_accuracy: 0.7980 - val_loss: 0.4934\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8309 - loss: 0.4628 - val_accuracy: 0.7980 - val_loss: 0.4870\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8073 - loss: 0.4765 - val_accuracy: 0.7980 - val_loss: 0.4819\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8238 - loss: 0.4712 - val_accuracy: 0.7980 - val_loss: 0.4814\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8310 - loss: 0.4332 - val_accuracy: 0.7980 - val_loss: 0.4821\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8387 - loss: 0.4204 - val_accuracy: 0.7980 - val_loss: 0.4802\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8360 - loss: 0.4546 - val_accuracy: 0.7980 - val_loss: 0.4814\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7976 - loss: 0.4674 - val_accuracy: 0.7980 - val_loss: 0.4752\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8205 - loss: 0.4546 - val_accuracy: 0.7980 - val_loss: 0.4756\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8283 - loss: 0.4315 - val_accuracy: 0.7980 - val_loss: 0.4792\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8147 - loss: 0.4757 - val_accuracy: 0.7980 - val_loss: 0.4745\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8507 - loss: 0.4014 - val_accuracy: 0.7980 - val_loss: 0.4770\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8255 - loss: 0.4388 - val_accuracy: 0.7980 - val_loss: 0.4768\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8084 - loss: 0.4660 - val_accuracy: 0.7879 - val_loss: 0.4745\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8413 - loss: 0.4270 - val_accuracy: 0.7879 - val_loss: 0.4724\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7988 - loss: 0.4295 - val_accuracy: 0.7879 - val_loss: 0.4746\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8276 - loss: 0.4438 - val_accuracy: 0.7879 - val_loss: 0.4777\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8242 - loss: 0.4195 - val_accuracy: 0.7879 - val_loss: 0.4773\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8376 - loss: 0.4001 - val_accuracy: 0.7879 - val_loss: 0.4749\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8269 - loss: 0.4421 - val_accuracy: 0.7980 - val_loss: 0.4745\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8329 - loss: 0.4257 - val_accuracy: 0.7980 - val_loss: 0.4789\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8189 - loss: 0.4745 - val_accuracy: 0.7980 - val_loss: 0.4815\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8400 - loss: 0.4072 - val_accuracy: 0.7980 - val_loss: 0.4786\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8296 - loss: 0.4679 - val_accuracy: 0.7980 - val_loss: 0.4791\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7940 - loss: 0.4720 - val_accuracy: 0.7980 - val_loss: 0.4769\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "✅ Test Accuracy: 78.86%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"1.simple_loan_data.csv\")\n",
    "\n",
    "# Step 2: Drop Loan_ID (not useful for prediction)\n",
    "df.drop(columns=[\"Loan_ID\"], inplace=True)\n",
    "\n",
    "# Step 3: Handle missing values\n",
    "# Fill categorical with mode\n",
    "for col in ['Gender', 'Married', 'Dependents', 'Self_Employed']:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Fill numeric with median\n",
    "for col in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Step 4: Encode categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Step 5: Split features and target\n",
    "X = df.drop(\"Loan_Status\", axis=1)\n",
    "y = df[\"Loan_Status\"]\n",
    "\n",
    "# Step 6: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 7: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Step 8: Build the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 9: Train the model\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=16, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Step 10: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_labels)\n",
    "print(f\"✅ Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361cc25",
   "metadata": {},
   "source": [
    "logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a21401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5359 - loss: 1.0035 - val_accuracy: 0.5051 - val_loss: 0.8931\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5515 - loss: 0.8868 - val_accuracy: 0.5051 - val_loss: 0.8749\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5592 - loss: 0.8876 - val_accuracy: 0.5051 - val_loss: 0.8573\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5741 - loss: 0.8430 - val_accuracy: 0.5051 - val_loss: 0.8409\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5275 - loss: 0.9056 - val_accuracy: 0.4949 - val_loss: 0.8240\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5554 - loss: 0.8443 - val_accuracy: 0.4949 - val_loss: 0.8071\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5909 - loss: 0.8107 - val_accuracy: 0.5152 - val_loss: 0.7916\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5750 - loss: 0.8185 - val_accuracy: 0.5152 - val_loss: 0.7768\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6211 - loss: 0.7626 - val_accuracy: 0.5152 - val_loss: 0.7629\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6011 - loss: 0.7759 - val_accuracy: 0.5253 - val_loss: 0.7482\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5774 - loss: 0.7912 - val_accuracy: 0.5152 - val_loss: 0.7344\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6441 - loss: 0.7016 - val_accuracy: 0.5051 - val_loss: 0.7226\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6157 - loss: 0.7422 - val_accuracy: 0.5253 - val_loss: 0.7094\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.6145 - loss: 0.7159 - val_accuracy: 0.5455 - val_loss: 0.6972\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6177 - loss: 0.7238 - val_accuracy: 0.5758 - val_loss: 0.6856\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5868 - loss: 0.7338 - val_accuracy: 0.5960 - val_loss: 0.6739\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6618 - loss: 0.6312 - val_accuracy: 0.6061 - val_loss: 0.6645\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6562 - loss: 0.6423 - val_accuracy: 0.6061 - val_loss: 0.6541\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6275 - loss: 0.6617 - val_accuracy: 0.6061 - val_loss: 0.6457\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6513 - loss: 0.6633 - val_accuracy: 0.6263 - val_loss: 0.6357\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6762 - loss: 0.6460 - val_accuracy: 0.6566 - val_loss: 0.6266\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6931 - loss: 0.6565 - val_accuracy: 0.6667 - val_loss: 0.6185\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7072 - loss: 0.6571 - val_accuracy: 0.6970 - val_loss: 0.6104\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7364 - loss: 0.6205 - val_accuracy: 0.7172 - val_loss: 0.6037\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7555 - loss: 0.5847 - val_accuracy: 0.7071 - val_loss: 0.5962\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7520 - loss: 0.5953 - val_accuracy: 0.7071 - val_loss: 0.5901\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7288 - loss: 0.6213 - val_accuracy: 0.7071 - val_loss: 0.5837\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7756 - loss: 0.5452 - val_accuracy: 0.7172 - val_loss: 0.5785\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7628 - loss: 0.5981 - val_accuracy: 0.7374 - val_loss: 0.5721\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7830 - loss: 0.5687 - val_accuracy: 0.7273 - val_loss: 0.5669\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8034 - loss: 0.5139 - val_accuracy: 0.7475 - val_loss: 0.5622\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7916 - loss: 0.5374 - val_accuracy: 0.7374 - val_loss: 0.5570\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7941 - loss: 0.5210 - val_accuracy: 0.7475 - val_loss: 0.5529\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7916 - loss: 0.5340 - val_accuracy: 0.7576 - val_loss: 0.5485\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7955 - loss: 0.5222 - val_accuracy: 0.7576 - val_loss: 0.5448\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7924 - loss: 0.5207 - val_accuracy: 0.7576 - val_loss: 0.5407\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7629 - loss: 0.5467 - val_accuracy: 0.7778 - val_loss: 0.5368\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8012 - loss: 0.5211 - val_accuracy: 0.7778 - val_loss: 0.5334\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7803 - loss: 0.5282 - val_accuracy: 0.7879 - val_loss: 0.5307\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8084 - loss: 0.5172 - val_accuracy: 0.7879 - val_loss: 0.5279\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8283 - loss: 0.4895 - val_accuracy: 0.7879 - val_loss: 0.5252\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7910 - loss: 0.5178 - val_accuracy: 0.7879 - val_loss: 0.5229\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7989 - loss: 0.5158 - val_accuracy: 0.7879 - val_loss: 0.5202\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8117 - loss: 0.4941 - val_accuracy: 0.7879 - val_loss: 0.5176\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8282 - loss: 0.4749 - val_accuracy: 0.7879 - val_loss: 0.5158\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8172 - loss: 0.4808 - val_accuracy: 0.7879 - val_loss: 0.5134\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7927 - loss: 0.5120 - val_accuracy: 0.7879 - val_loss: 0.5119\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8321 - loss: 0.4775 - val_accuracy: 0.7879 - val_loss: 0.5104\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8213 - loss: 0.4932 - val_accuracy: 0.7879 - val_loss: 0.5090\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7900 - loss: 0.5217 - val_accuracy: 0.7980 - val_loss: 0.5077\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8305 - loss: 0.4843 - val_accuracy: 0.7980 - val_loss: 0.5057\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8243 - loss: 0.4793 - val_accuracy: 0.7980 - val_loss: 0.5046\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7966 - loss: 0.5214 - val_accuracy: 0.7980 - val_loss: 0.5035\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8076 - loss: 0.5005 - val_accuracy: 0.7980 - val_loss: 0.5019\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8547 - loss: 0.4409 - val_accuracy: 0.7980 - val_loss: 0.5010\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7823 - loss: 0.5218 - val_accuracy: 0.7980 - val_loss: 0.5002\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8206 - loss: 0.4779 - val_accuracy: 0.7980 - val_loss: 0.4991\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8303 - loss: 0.4684 - val_accuracy: 0.7980 - val_loss: 0.4983\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8151 - loss: 0.4803 - val_accuracy: 0.7980 - val_loss: 0.4973\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8109 - loss: 0.4877 - val_accuracy: 0.7980 - val_loss: 0.4964\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8324 - loss: 0.4610 - val_accuracy: 0.7980 - val_loss: 0.4962\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8063 - loss: 0.4862 - val_accuracy: 0.7980 - val_loss: 0.4953\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8004 - loss: 0.4806 - val_accuracy: 0.7980 - val_loss: 0.4950\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8085 - loss: 0.4888 - val_accuracy: 0.7980 - val_loss: 0.4940\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8002 - loss: 0.4957 - val_accuracy: 0.7980 - val_loss: 0.4941\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8250 - loss: 0.4706 - val_accuracy: 0.7980 - val_loss: 0.4933\n",
      "Epoch 67/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8246 - loss: 0.4686 - val_accuracy: 0.7980 - val_loss: 0.4927\n",
      "Epoch 68/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8198 - loss: 0.4710 - val_accuracy: 0.7980 - val_loss: 0.4924\n",
      "Epoch 69/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8262 - loss: 0.4567 - val_accuracy: 0.7980 - val_loss: 0.4919\n",
      "Epoch 70/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8251 - loss: 0.4596 - val_accuracy: 0.7980 - val_loss: 0.4911\n",
      "Epoch 71/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8335 - loss: 0.4427 - val_accuracy: 0.7980 - val_loss: 0.4910\n",
      "Epoch 72/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8303 - loss: 0.4505 - val_accuracy: 0.7980 - val_loss: 0.4907\n",
      "Epoch 73/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8028 - loss: 0.4870 - val_accuracy: 0.7980 - val_loss: 0.4903\n",
      "Epoch 74/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8401 - loss: 0.4490 - val_accuracy: 0.7980 - val_loss: 0.4899\n",
      "Epoch 75/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8318 - loss: 0.4540 - val_accuracy: 0.7980 - val_loss: 0.4896\n",
      "Epoch 76/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8071 - loss: 0.4886 - val_accuracy: 0.7980 - val_loss: 0.4896\n",
      "Epoch 77/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8143 - loss: 0.4665 - val_accuracy: 0.7980 - val_loss: 0.4887\n",
      "Epoch 78/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8202 - loss: 0.4581 - val_accuracy: 0.7980 - val_loss: 0.4892\n",
      "Epoch 79/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8452 - loss: 0.4312 - val_accuracy: 0.7980 - val_loss: 0.4892\n",
      "Epoch 80/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8339 - loss: 0.4475 - val_accuracy: 0.7980 - val_loss: 0.4886\n",
      "Epoch 81/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8321 - loss: 0.4542 - val_accuracy: 0.7980 - val_loss: 0.4882\n",
      "Epoch 82/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8175 - loss: 0.4707 - val_accuracy: 0.7980 - val_loss: 0.4880\n",
      "Epoch 83/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8328 - loss: 0.4508 - val_accuracy: 0.7980 - val_loss: 0.4881\n",
      "Epoch 84/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.4593 - val_accuracy: 0.7980 - val_loss: 0.4885\n",
      "Epoch 85/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8234 - loss: 0.4611 - val_accuracy: 0.7980 - val_loss: 0.4881\n",
      "Epoch 86/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.4128 - val_accuracy: 0.7980 - val_loss: 0.4888\n",
      "Epoch 87/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8499 - loss: 0.4308 - val_accuracy: 0.7980 - val_loss: 0.4888\n",
      "Epoch 88/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8126 - loss: 0.4695 - val_accuracy: 0.7980 - val_loss: 0.4880\n",
      "Epoch 89/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8198 - loss: 0.4615 - val_accuracy: 0.7980 - val_loss: 0.4880\n",
      "Epoch 90/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 0.4298 - val_accuracy: 0.7980 - val_loss: 0.4874\n",
      "Epoch 91/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8524 - loss: 0.4246 - val_accuracy: 0.7980 - val_loss: 0.4876\n",
      "Epoch 92/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8027 - loss: 0.4770 - val_accuracy: 0.7980 - val_loss: 0.4872\n",
      "Epoch 93/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8256 - loss: 0.4688 - val_accuracy: 0.7980 - val_loss: 0.4875\n",
      "Epoch 94/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8289 - loss: 0.4547 - val_accuracy: 0.7980 - val_loss: 0.4873\n",
      "Epoch 95/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7930 - loss: 0.4991 - val_accuracy: 0.7980 - val_loss: 0.4871\n",
      "Epoch 96/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8267 - loss: 0.4460 - val_accuracy: 0.7980 - val_loss: 0.4872\n",
      "Epoch 97/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8322 - loss: 0.4317 - val_accuracy: 0.7980 - val_loss: 0.4870\n",
      "Epoch 98/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8285 - loss: 0.4583 - val_accuracy: 0.7980 - val_loss: 0.4874\n",
      "Epoch 99/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8013 - loss: 0.4967 - val_accuracy: 0.7980 - val_loss: 0.4869\n",
      "Epoch 100/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8406 - loss: 0.4353 - val_accuracy: 0.7980 - val_loss: 0.4869\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "🔸 Logistic_Model Accuracy: 0.7886178861788617\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(1, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=16, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "y_pred2 = (model2.predict(X_test) > 0.5).astype(int)\n",
    "print(\"🔸 Logistic_Model Accuracy:\", accuracy_score(y_test, y_pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b2a46",
   "metadata": {},
   "source": [
    "tiny overfit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24bb45d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niraj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.2977 - loss: 0.8454 - val_accuracy: 0.4949 - val_loss: 0.7440\n",
      "Epoch 2/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4785 - loss: 0.7535 - val_accuracy: 0.5758 - val_loss: 0.7038\n",
      "Epoch 3/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5776 - loss: 0.7189 - val_accuracy: 0.6465 - val_loss: 0.6791\n",
      "Epoch 4/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6796 - loss: 0.6685 - val_accuracy: 0.6465 - val_loss: 0.6636\n",
      "Epoch 5/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6641 - loss: 0.6710 - val_accuracy: 0.6768 - val_loss: 0.6503\n",
      "Epoch 6/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7335 - loss: 0.6347 - val_accuracy: 0.6869 - val_loss: 0.6375\n",
      "Epoch 7/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7035 - loss: 0.6421 - val_accuracy: 0.6970 - val_loss: 0.6260\n",
      "Epoch 8/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7491 - loss: 0.6115 - val_accuracy: 0.7071 - val_loss: 0.6148\n",
      "Epoch 9/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7286 - loss: 0.6073 - val_accuracy: 0.7172 - val_loss: 0.6024\n",
      "Epoch 10/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6998 - loss: 0.6052 - val_accuracy: 0.7172 - val_loss: 0.5909\n",
      "Epoch 11/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7519 - loss: 0.5799 - val_accuracy: 0.7273 - val_loss: 0.5783\n",
      "Epoch 12/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7772 - loss: 0.5637 - val_accuracy: 0.7374 - val_loss: 0.5663\n",
      "Epoch 13/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7902 - loss: 0.5189 - val_accuracy: 0.7374 - val_loss: 0.5473\n",
      "Epoch 14/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7942 - loss: 0.5141 - val_accuracy: 0.7576 - val_loss: 0.5338\n",
      "Epoch 15/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7754 - loss: 0.5504 - val_accuracy: 0.7778 - val_loss: 0.5214\n",
      "Epoch 16/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8062 - loss: 0.4970 - val_accuracy: 0.7778 - val_loss: 0.5101\n",
      "Epoch 17/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8058 - loss: 0.4959 - val_accuracy: 0.7980 - val_loss: 0.4986\n",
      "Epoch 18/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8358 - loss: 0.4628 - val_accuracy: 0.7980 - val_loss: 0.4877\n",
      "Epoch 19/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8277 - loss: 0.4614 - val_accuracy: 0.7980 - val_loss: 0.4822\n",
      "Epoch 20/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8099 - loss: 0.4844 - val_accuracy: 0.7980 - val_loss: 0.4764\n",
      "Epoch 21/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8232 - loss: 0.4674 - val_accuracy: 0.7980 - val_loss: 0.4721\n",
      "Epoch 22/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8130 - loss: 0.4788 - val_accuracy: 0.7980 - val_loss: 0.4677\n",
      "Epoch 23/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8328 - loss: 0.4561 - val_accuracy: 0.7980 - val_loss: 0.4649\n",
      "Epoch 24/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8190 - loss: 0.4574 - val_accuracy: 0.7980 - val_loss: 0.4630\n",
      "Epoch 25/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8289 - loss: 0.4574 - val_accuracy: 0.7980 - val_loss: 0.4622\n",
      "Epoch 26/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7988 - loss: 0.4828 - val_accuracy: 0.7980 - val_loss: 0.4611\n",
      "Epoch 27/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8104 - loss: 0.4865 - val_accuracy: 0.7980 - val_loss: 0.4609\n",
      "Epoch 28/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8206 - loss: 0.4618 - val_accuracy: 0.7980 - val_loss: 0.4593\n",
      "Epoch 29/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8407 - loss: 0.4339 - val_accuracy: 0.7980 - val_loss: 0.4577\n",
      "Epoch 30/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8470 - loss: 0.4226 - val_accuracy: 0.7980 - val_loss: 0.4566\n",
      "Epoch 31/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8410 - loss: 0.4250 - val_accuracy: 0.7980 - val_loss: 0.4557\n",
      "Epoch 32/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8421 - loss: 0.4151 - val_accuracy: 0.7980 - val_loss: 0.4556\n",
      "Epoch 33/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8474 - loss: 0.3999 - val_accuracy: 0.7980 - val_loss: 0.4540\n",
      "Epoch 34/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8394 - loss: 0.4048 - val_accuracy: 0.7980 - val_loss: 0.4527\n",
      "Epoch 35/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8383 - loss: 0.4362 - val_accuracy: 0.7980 - val_loss: 0.4535\n",
      "Epoch 36/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8401 - loss: 0.4138 - val_accuracy: 0.7980 - val_loss: 0.4511\n",
      "Epoch 37/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8677 - loss: 0.3822 - val_accuracy: 0.7980 - val_loss: 0.4513\n",
      "Epoch 38/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8445 - loss: 0.4047 - val_accuracy: 0.7980 - val_loss: 0.4501\n",
      "Epoch 39/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8125 - loss: 0.4557 - val_accuracy: 0.7980 - val_loss: 0.4497\n",
      "Epoch 40/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8344 - loss: 0.4111 - val_accuracy: 0.7980 - val_loss: 0.4479\n",
      "Epoch 41/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8339 - loss: 0.4278 - val_accuracy: 0.7980 - val_loss: 0.4473\n",
      "Epoch 42/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8396 - loss: 0.4119 - val_accuracy: 0.7980 - val_loss: 0.4469\n",
      "Epoch 43/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8489 - loss: 0.4013 - val_accuracy: 0.7980 - val_loss: 0.4464\n",
      "Epoch 44/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8532 - loss: 0.3917 - val_accuracy: 0.7980 - val_loss: 0.4457\n",
      "Epoch 45/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8358 - loss: 0.4164 - val_accuracy: 0.7980 - val_loss: 0.4458\n",
      "Epoch 46/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8362 - loss: 0.4019 - val_accuracy: 0.7980 - val_loss: 0.4438\n",
      "Epoch 47/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8492 - loss: 0.3909 - val_accuracy: 0.7980 - val_loss: 0.4441\n",
      "Epoch 48/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8522 - loss: 0.3943 - val_accuracy: 0.7980 - val_loss: 0.4447\n",
      "Epoch 49/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8483 - loss: 0.4125 - val_accuracy: 0.7980 - val_loss: 0.4447\n",
      "Epoch 50/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8610 - loss: 0.3748 - val_accuracy: 0.7980 - val_loss: 0.4409\n",
      "Epoch 51/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8486 - loss: 0.4008 - val_accuracy: 0.7980 - val_loss: 0.4409\n",
      "Epoch 52/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8644 - loss: 0.3731 - val_accuracy: 0.7980 - val_loss: 0.4393\n",
      "Epoch 53/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8411 - loss: 0.3936 - val_accuracy: 0.7980 - val_loss: 0.4389\n",
      "Epoch 54/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.4056 - val_accuracy: 0.7980 - val_loss: 0.4359\n",
      "Epoch 55/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8533 - loss: 0.3847 - val_accuracy: 0.7980 - val_loss: 0.4373\n",
      "Epoch 56/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8380 - loss: 0.4018 - val_accuracy: 0.7980 - val_loss: 0.4370\n",
      "Epoch 57/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8279 - loss: 0.4083 - val_accuracy: 0.7980 - val_loss: 0.4351\n",
      "Epoch 58/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8399 - loss: 0.3987 - val_accuracy: 0.7980 - val_loss: 0.4373\n",
      "Epoch 59/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8163 - loss: 0.4246 - val_accuracy: 0.8081 - val_loss: 0.4351\n",
      "Epoch 60/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8279 - loss: 0.4071 - val_accuracy: 0.8081 - val_loss: 0.4342\n",
      "Epoch 61/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8513 - loss: 0.3792 - val_accuracy: 0.8182 - val_loss: 0.4333\n",
      "Epoch 62/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8471 - loss: 0.3891 - val_accuracy: 0.8182 - val_loss: 0.4323\n",
      "Epoch 63/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8593 - loss: 0.3692 - val_accuracy: 0.8182 - val_loss: 0.4320\n",
      "Epoch 64/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8454 - loss: 0.3867 - val_accuracy: 0.8182 - val_loss: 0.4326\n",
      "Epoch 65/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8373 - loss: 0.4018 - val_accuracy: 0.8182 - val_loss: 0.4314\n",
      "Epoch 66/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8380 - loss: 0.3872 - val_accuracy: 0.8182 - val_loss: 0.4301\n",
      "Epoch 67/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8312 - loss: 0.4201 - val_accuracy: 0.8182 - val_loss: 0.4298\n",
      "Epoch 68/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8521 - loss: 0.3731 - val_accuracy: 0.8182 - val_loss: 0.4304\n",
      "Epoch 69/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8533 - loss: 0.3566 - val_accuracy: 0.8182 - val_loss: 0.4304\n",
      "Epoch 70/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8519 - loss: 0.3824 - val_accuracy: 0.8182 - val_loss: 0.4305\n",
      "Epoch 71/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.3471 - val_accuracy: 0.8182 - val_loss: 0.4313\n",
      "Epoch 72/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8423 - loss: 0.3913 - val_accuracy: 0.8182 - val_loss: 0.4290\n",
      "Epoch 73/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8809 - loss: 0.3222 - val_accuracy: 0.8182 - val_loss: 0.4305\n",
      "Epoch 74/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8800 - loss: 0.3420 - val_accuracy: 0.8182 - val_loss: 0.4267\n",
      "Epoch 75/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8627 - loss: 0.3479 - val_accuracy: 0.8182 - val_loss: 0.4277\n",
      "Epoch 76/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8454 - loss: 0.3781 - val_accuracy: 0.8182 - val_loss: 0.4306\n",
      "Epoch 77/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8546 - loss: 0.3874 - val_accuracy: 0.8182 - val_loss: 0.4289\n",
      "Epoch 78/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8500 - loss: 0.3757 - val_accuracy: 0.8182 - val_loss: 0.4295\n",
      "Epoch 79/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8647 - loss: 0.3397 - val_accuracy: 0.8182 - val_loss: 0.4285\n",
      "Epoch 80/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8629 - loss: 0.3684 - val_accuracy: 0.8182 - val_loss: 0.4258\n",
      "Epoch 81/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8227 - loss: 0.4026 - val_accuracy: 0.8182 - val_loss: 0.4288\n",
      "Epoch 82/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8589 - loss: 0.3398 - val_accuracy: 0.8182 - val_loss: 0.4295\n",
      "Epoch 83/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8032 - loss: 0.4573 - val_accuracy: 0.8182 - val_loss: 0.4277\n",
      "Epoch 84/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8583 - loss: 0.3598 - val_accuracy: 0.8182 - val_loss: 0.4266\n",
      "Epoch 85/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8380 - loss: 0.3788 - val_accuracy: 0.8182 - val_loss: 0.4275\n",
      "Epoch 86/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8731 - loss: 0.3546 - val_accuracy: 0.8182 - val_loss: 0.4281\n",
      "Epoch 87/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8785 - loss: 0.3500 - val_accuracy: 0.8182 - val_loss: 0.4259\n",
      "Epoch 88/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8547 - loss: 0.3589 - val_accuracy: 0.8182 - val_loss: 0.4268\n",
      "Epoch 89/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8554 - loss: 0.3594 - val_accuracy: 0.8182 - val_loss: 0.4242\n",
      "Epoch 90/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8667 - loss: 0.3414 - val_accuracy: 0.8182 - val_loss: 0.4259\n",
      "Epoch 91/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8255 - loss: 0.4228 - val_accuracy: 0.8182 - val_loss: 0.4291\n",
      "Epoch 92/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8533 - loss: 0.3968 - val_accuracy: 0.8182 - val_loss: 0.4286\n",
      "Epoch 93/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8454 - loss: 0.3680 - val_accuracy: 0.8182 - val_loss: 0.4268\n",
      "Epoch 94/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8735 - loss: 0.3260 - val_accuracy: 0.8182 - val_loss: 0.4270\n",
      "Epoch 95/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8734 - loss: 0.3476 - val_accuracy: 0.8182 - val_loss: 0.4267\n",
      "Epoch 96/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8578 - loss: 0.3918 - val_accuracy: 0.8182 - val_loss: 0.4249\n",
      "Epoch 97/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8439 - loss: 0.3755 - val_accuracy: 0.8182 - val_loss: 0.4253\n",
      "Epoch 98/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8674 - loss: 0.3443 - val_accuracy: 0.8182 - val_loss: 0.4256\n",
      "Epoch 99/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8400 - loss: 0.3891 - val_accuracy: 0.8182 - val_loss: 0.4250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "🔸 Tiny_Overfit_Model Accuracy: 0.7723577235772358\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(8, input_dim=X_train.shape[1], activation='relu'))\n",
    "model3.add(Dense(4, activation='relu'))\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=8, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "y_pred3 = (model3.predict(X_test) > 0.5).astype(int)\n",
    "print(\"🔸 Tiny_Overfit_Model Accuracy:\", accuracy_score(y_test, y_pred3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52243b9",
   "metadata": {},
   "source": [
    "deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e13e0644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niraj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Model 2 Accuracy: 0.7886178861788617\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=16, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "y_pred2 = (model2.predict(X_test) > 0.5).astype(int)\n",
    "print(\"Model 2 Accuracy:\", accuracy_score(y_test, y_pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610818dc",
   "metadata": {},
   "source": [
    "cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893c4899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niraj\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.5346 - loss: 0.7136 - val_accuracy: 0.7475 - val_loss: 0.6568\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.7680 - loss: 0.6253 - val_accuracy: 0.7475 - val_loss: 0.6173\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7552 - loss: 0.5877 - val_accuracy: 0.7778 - val_loss: 0.5840\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7623 - loss: 0.5555 - val_accuracy: 0.7677 - val_loss: 0.5635\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.7962 - loss: 0.5268 - val_accuracy: 0.7677 - val_loss: 0.5446\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8421 - loss: 0.5029 - val_accuracy: 0.7677 - val_loss: 0.5354\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8152 - loss: 0.4687 - val_accuracy: 0.7677 - val_loss: 0.5260\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8557 - loss: 0.4332 - val_accuracy: 0.7677 - val_loss: 0.5221\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8228 - loss: 0.4620 - val_accuracy: 0.7677 - val_loss: 0.5205\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8222 - loss: 0.4757 - val_accuracy: 0.7778 - val_loss: 0.5170\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8329 - loss: 0.4535 - val_accuracy: 0.7677 - val_loss: 0.5158\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8577 - loss: 0.4217 - val_accuracy: 0.7778 - val_loss: 0.5130\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8210 - loss: 0.4632 - val_accuracy: 0.7677 - val_loss: 0.5079\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8674 - loss: 0.4157 - val_accuracy: 0.7879 - val_loss: 0.5105\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8641 - loss: 0.4073 - val_accuracy: 0.7677 - val_loss: 0.5042\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8499 - loss: 0.4175 - val_accuracy: 0.7677 - val_loss: 0.5025\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8124 - loss: 0.4750 - val_accuracy: 0.7879 - val_loss: 0.4938\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8387 - loss: 0.4356 - val_accuracy: 0.7677 - val_loss: 0.4932\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8244 - loss: 0.4529 - val_accuracy: 0.7778 - val_loss: 0.4900\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8093 - loss: 0.4490 - val_accuracy: 0.7879 - val_loss: 0.4928\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8206 - loss: 0.4392 - val_accuracy: 0.7778 - val_loss: 0.4905\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8048 - loss: 0.4659 - val_accuracy: 0.7879 - val_loss: 0.4916\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8489 - loss: 0.4220 - val_accuracy: 0.7879 - val_loss: 0.4950\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8303 - loss: 0.4229 - val_accuracy: 0.7879 - val_loss: 0.4944\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8211 - loss: 0.4612 - val_accuracy: 0.7778 - val_loss: 0.4934\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8210 - loss: 0.4404 - val_accuracy: 0.7879 - val_loss: 0.4871\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.7784 - loss: 0.5029 - val_accuracy: 0.7778 - val_loss: 0.4857\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8428 - loss: 0.4471 - val_accuracy: 0.7879 - val_loss: 0.4845\n",
      "Epoch 29/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8473 - loss: 0.4200 - val_accuracy: 0.7778 - val_loss: 0.4888\n",
      "Epoch 30/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8374 - loss: 0.4585 - val_accuracy: 0.7778 - val_loss: 0.4816\n",
      "Epoch 31/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8096 - loss: 0.4758 - val_accuracy: 0.7778 - val_loss: 0.4833\n",
      "Epoch 32/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8535 - loss: 0.3990 - val_accuracy: 0.7879 - val_loss: 0.4833\n",
      "Epoch 33/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8170 - loss: 0.4419 - val_accuracy: 0.7778 - val_loss: 0.4805\n",
      "Epoch 34/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8361 - loss: 0.4164 - val_accuracy: 0.7778 - val_loss: 0.4843\n",
      "Epoch 35/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8266 - loss: 0.4362 - val_accuracy: 0.7778 - val_loss: 0.4795\n",
      "Epoch 36/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8369 - loss: 0.4184 - val_accuracy: 0.7778 - val_loss: 0.4806\n",
      "Epoch 37/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8400 - loss: 0.4054 - val_accuracy: 0.7778 - val_loss: 0.4796\n",
      "Epoch 38/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8238 - loss: 0.4354 - val_accuracy: 0.7778 - val_loss: 0.4796\n",
      "Epoch 39/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8445 - loss: 0.4249 - val_accuracy: 0.7778 - val_loss: 0.4796\n",
      "Epoch 40/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8381 - loss: 0.4173 - val_accuracy: 0.7778 - val_loss: 0.4770\n",
      "Epoch 41/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8080 - loss: 0.4547 - val_accuracy: 0.7778 - val_loss: 0.4809\n",
      "Epoch 42/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8295 - loss: 0.4267 - val_accuracy: 0.7778 - val_loss: 0.4796\n",
      "Epoch 43/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8410 - loss: 0.4005 - val_accuracy: 0.7778 - val_loss: 0.4812\n",
      "Epoch 44/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8484 - loss: 0.4302 - val_accuracy: 0.7980 - val_loss: 0.4785\n",
      "Epoch 45/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8306 - loss: 0.4291 - val_accuracy: 0.7879 - val_loss: 0.4771\n",
      "Epoch 46/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8503 - loss: 0.3869 - val_accuracy: 0.7879 - val_loss: 0.4830\n",
      "Epoch 47/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8391 - loss: 0.4513 - val_accuracy: 0.7879 - val_loss: 0.4842\n",
      "Epoch 48/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8510 - loss: 0.4049 - val_accuracy: 0.8081 - val_loss: 0.4755\n",
      "Epoch 49/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8494 - loss: 0.4034 - val_accuracy: 0.7980 - val_loss: 0.4782\n",
      "Epoch 50/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8718 - loss: 0.3647 - val_accuracy: 0.7980 - val_loss: 0.4820\n",
      "Epoch 51/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8269 - loss: 0.4272 - val_accuracy: 0.7980 - val_loss: 0.4774\n",
      "Epoch 52/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8498 - loss: 0.3992 - val_accuracy: 0.7980 - val_loss: 0.4805\n",
      "Epoch 53/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8582 - loss: 0.4209 - val_accuracy: 0.7980 - val_loss: 0.4781\n",
      "Epoch 54/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8515 - loss: 0.3940 - val_accuracy: 0.7980 - val_loss: 0.4805\n",
      "Epoch 55/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8513 - loss: 0.4154 - val_accuracy: 0.8182 - val_loss: 0.4736\n",
      "Epoch 56/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8541 - loss: 0.3987 - val_accuracy: 0.7980 - val_loss: 0.4728\n",
      "Epoch 57/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8322 - loss: 0.4481 - val_accuracy: 0.7980 - val_loss: 0.4782\n",
      "Epoch 58/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8415 - loss: 0.4293 - val_accuracy: 0.7980 - val_loss: 0.4772\n",
      "Epoch 59/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8702 - loss: 0.3811 - val_accuracy: 0.7980 - val_loss: 0.4745\n",
      "Epoch 60/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8627 - loss: 0.3652 - val_accuracy: 0.7980 - val_loss: 0.4820\n",
      "Epoch 61/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8332 - loss: 0.3949 - val_accuracy: 0.8081 - val_loss: 0.4789\n",
      "Epoch 62/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8556 - loss: 0.3797 - val_accuracy: 0.7980 - val_loss: 0.4845\n",
      "Epoch 63/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8462 - loss: 0.4160 - val_accuracy: 0.7980 - val_loss: 0.4847\n",
      "Epoch 64/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8559 - loss: 0.4012 - val_accuracy: 0.7980 - val_loss: 0.4813\n",
      "Epoch 65/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7961 - loss: 0.4399 - val_accuracy: 0.7980 - val_loss: 0.4779\n",
      "Epoch 66/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8378 - loss: 0.4065 - val_accuracy: 0.7980 - val_loss: 0.4820\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "🔹 CNN Model Accuracy: 0.7642276422764228\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Reshape\n",
    "\n",
    "# Reshape X data for Conv1D: (samples, timesteps, features) => treat each feature as a timestep\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Build CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(16, activation='relu'))\n",
    "cnn_model.add(Dropout(0.3))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN model\n",
    "history_cnn = cnn_model.fit(X_train_cnn, y_train, validation_split=0.2, epochs=100, batch_size=16, callbacks=[early_stop], verbose=1)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_cnn = (cnn_model.predict(X_test_cnn) > 0.5).astype(int)\n",
    "print(\"🔹 CNN Model Accuracy:\", accuracy_score(y_test, y_pred_cnn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
